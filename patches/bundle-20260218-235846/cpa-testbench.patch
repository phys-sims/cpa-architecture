diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
index 8b4808a..5bcf7c3 100644
--- a/.github/workflows/ci.yml
+++ b/.github/workflows/ci.yml
@@ -10,10 +10,10 @@ jobs:
   build:
     runs-on: ubuntu-latest
     steps:
-      - uses: actions/checkout@v3
+      - uses: actions/checkout@v4
 
       - name: Set up Python
-        uses: actions/setup-python@v4
+        uses: actions/setup-python@v5
         with:
           python-version: "3.11"
 
@@ -25,9 +25,8 @@ jobs:
       - name: Lint & Typecheck
         run: |
           black --check .
-          isort --check --diff .
-          flake8 src tests
+          ruff check .
           mypy src
 
       - name: Tests
-        run: pytest -q
+        run: pytest
diff --git a/README.md b/README.md
index b6016c4..cc6fb73 100644
--- a/README.md
+++ b/README.md
@@ -1,16 +1,40 @@
 # cpa-testbench
 
-Private research testbench scaffold.
+Agent-ready research testbench scaffold for config-driven CPA experiments.
 
 ## Features
-- Config-driven experiments (`configs/`)
-- Scripts to run pipelines (`scripts/`)
-- Conda environment (`environment.yml`)
-- CI via GitHub Actions
+- Installable Python package (`src/cpa_testbench`) with CLI entrypoint.
+- Config-driven experiments (`configs/`).
+- Script and module execution for pipeline runs.
+- CI and local tooling aligned with `cpa-sim` style (black + ruff + mypy + pytest).
 
 ## Setup
 
 ```bash
-conda env create -f environment.yml
-conda activate mytestbench-env
-pip install -e .
+python -m pip install --upgrade pip
+pip install -e .[dev]
+```
+
+## Run
+
+```bash
+# via script wrapper
+python scripts/run_pipeline.py --config configs/pipeline.yaml
+
+# via installed console script
+cpa-testbench --config configs/pipeline.yaml
+```
+
+## Agentic usage pattern
+
+1. Keep experiment definitions in YAML under `configs/`.
+2. Execute with the `cpa-testbench` CLI so runs are reproducible.
+3. Extend `cpa_testbench.pipeline` with concrete `cpa-sim` stage execution logic.
+4. Validate with:
+
+```bash
+black --check .
+ruff check .
+mypy src
+pytest
+```
diff --git a/pyproject.toml b/pyproject.toml
index 803a3a2..d963d0d 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,34 +1,63 @@
+[build-system]
+requires = ["setuptools>=68", "wheel"]
+build-backend = "setuptools.build_meta"
 
 [project]
 name = "cpa-testbench"
 version = "0.1.0"
-description = "Private research testbench"
+description = "Agent-ready research testbench for CPA pipeline experiments"
 authors = [{ name = "Ryaan Lari" }]
 readme = "README.md"
-requires-python = ">= 3.11"
+requires-python = ">=3.11"
 dependencies = [
   "pyyaml",
+  "cpa-sim @ git+https://github.com/phys-sims/cpa-sim.git@0a445de1a2db2fbf19c5f77fd4eed4f075038e8f",
+  "phys-sims-utils @ git+https://github.com/phys-sims/phys-sims-utils.git@dddeea9c0a988acf37eb1e22eae6d587dd7e6871",
 ]
 
+[project.scripts]
+cpa-testbench = "cpa_testbench.cli:main"
+
 [project.optional-dependencies]
 dev = [
   "pytest",
   "black",
-  "isort",
-  "flake8",
-  "mypy"
+  "ruff",
+  "mypy",
+  "pre-commit",
 ]
 
+[tool.setuptools]
+package-dir = { "" = "src" }
+
+[tool.setuptools.packages.find]
+where = ["src"]
+include = ["cpa_testbench*"]
+
 [tool.black]
 line-length = 100
 
-[tool.isort]
-profile = "black"
+[tool.ruff]
+line-length = 100
+target-version = "py311"
 
-[tool.flake8]
-max-line-length = 100
-extend-ignore = ["E203"]
+[tool.ruff.lint]
+select = ["E", "F", "I", "UP"]
 
 [tool.mypy]
 python_version = "3.11"
+warn_unused_ignores = true
+warn_redundant_casts = true
+warn_unused_configs = true
+disallow_untyped_defs = true
+mypy_path = "src"
+files = "src"
+
+[[tool.mypy.overrides]]
+module = ["yaml"]
 ignore_missing_imports = true
+
+[tool.pytest.ini_options]
+pythonpath = ["src"]
+addopts = "-q"
+testpaths = ["tests"]
diff --git a/scripts/run_pipeline.py b/scripts/run_pipeline.py
index f5e1657..63d7349 100644
--- a/scripts/run_pipeline.py
+++ b/scripts/run_pipeline.py
@@ -1,23 +1,5 @@
-import argparse
-from pathlib import Path
-import yaml
+from cpa_testbench.cli import main
 
-def main():
-    parser = argparse.ArgumentParser()
-    parser.add_argument("--config", default="configs/pipeline.yaml")
-    args = parser.parse_args()
-
-    cfg = yaml.safe_load(Path(args.config).read_text())
-
-    # Example: resolve stages from config; replace with your actual libs
-    stages = []
-    for s in cfg.get("stages", []):
-        # Here you would import from abcdef-sim or cpa-sim
-        # For now, just collect dicts
-        stages.append(s)
-
-    print("Loaded config with", len(stages), "stages.")
-    # TODO: run your real pipeline; emit logs to cfg['logging']['logfile']
 
 if __name__ == "__main__":
     main()
diff --git a/src/cpa_testbench/__init__.py b/src/cpa_testbench/__init__.py
index e69de29..eaab311 100644
--- a/src/cpa_testbench/__init__.py
+++ b/src/cpa_testbench/__init__.py
@@ -0,0 +1,3 @@
+from cpa_testbench.pipeline import run_pipeline
+
+__all__ = ["run_pipeline"]
diff --git a/src/cpa_testbench/cli.py b/src/cpa_testbench/cli.py
new file mode 100644
index 0000000..ce8f802
--- /dev/null
+++ b/src/cpa_testbench/cli.py
@@ -0,0 +1,26 @@
+from __future__ import annotations
+
+import argparse
+from pathlib import Path
+
+from cpa_testbench.pipeline import DEFAULT_CONFIG_PATH, run_pipeline
+
+
+def build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Run the cpa-testbench pipeline.")
+    parser.add_argument(
+        "--config",
+        type=Path,
+        default=DEFAULT_CONFIG_PATH,
+        help="Path to pipeline YAML config file.",
+    )
+    return parser
+
+
+def main() -> None:
+    args = build_parser().parse_args()
+    run_pipeline(config_path=args.config)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/src/cpa_testbench/pipeline.py b/src/cpa_testbench/pipeline.py
new file mode 100644
index 0000000..7b1a4fe
--- /dev/null
+++ b/src/cpa_testbench/pipeline.py
@@ -0,0 +1,42 @@
+from __future__ import annotations
+
+from pathlib import Path
+from typing import Any
+
+import yaml
+
+
+DEFAULT_CONFIG_PATH = Path("configs/pipeline.yaml")
+
+
+def load_pipeline_config(config_path: Path) -> dict[str, Any]:
+    """Load and validate a testbench configuration file."""
+    loaded = yaml.safe_load(config_path.read_text())
+    if not isinstance(loaded, dict):
+        msg = f"Config at {config_path} must deserialize to a mapping."
+        raise ValueError(msg)
+    return loaded
+
+
+def resolve_stages(config: dict[str, Any]) -> list[dict[str, Any]]:
+    """Resolve configured stages into normalized dictionaries."""
+    raw_stages = config.get("stages", [])
+    if not isinstance(raw_stages, list):
+        msg = "Config key 'stages' must be a list."
+        raise ValueError(msg)
+
+    stages: list[dict[str, Any]] = []
+    for index, stage in enumerate(raw_stages):
+        if not isinstance(stage, dict):
+            msg = f"Stage at index {index} must be a mapping."
+            raise ValueError(msg)
+        stages.append(stage)
+    return stages
+
+
+def run_pipeline(config_path: Path = DEFAULT_CONFIG_PATH) -> int:
+    """Load config and execute a placeholder pipeline run."""
+    config = load_pipeline_config(config_path)
+    stages = resolve_stages(config)
+    print(f"Loaded config with {len(stages)} stages.")
+    return len(stages)
diff --git a/tests/test_e2e.py b/tests/test_e2e.py
index 7be9c70..d50271f 100644
--- a/tests/test_e2e.py
+++ b/tests/test_e2e.py
@@ -1,6 +1,37 @@
-from subprocess import run, PIPE
+from __future__ import annotations
 
-def test_pipeline_script_runs():
-    p = run(["python", "scripts/run_pipeline.py"], stdout=PIPE, stderr=PIPE, text=True)
-    assert p.returncode == 0
-    assert "Loaded config" in p.stdout
+from pathlib import Path
+from subprocess import PIPE, run
+
+import pytest
+
+from cpa_testbench.pipeline import load_pipeline_config, run_pipeline
+
+
+ROOT = Path(__file__).resolve().parents[1]
+
+
+def test_pipeline_script_runs() -> None:
+    process = run(
+        ["python", "scripts/run_pipeline.py"],
+        cwd=ROOT,
+        stdout=PIPE,
+        stderr=PIPE,
+        text=True,
+        check=False,
+    )
+    assert process.returncode == 0
+    assert "Loaded config" in process.stdout
+
+
+def test_run_pipeline_returns_stage_count() -> None:
+    count = run_pipeline(config_path=ROOT / "configs" / "pipeline.yaml")
+    assert count == 3
+
+
+def test_load_pipeline_requires_mapping(tmp_path: Path) -> None:
+    invalid = tmp_path / "invalid.yaml"
+    invalid.write_text("- not\n- a\n- mapping\n")
+
+    with pytest.raises(ValueError, match="must deserialize to a mapping"):
+        load_pipeline_config(invalid)
